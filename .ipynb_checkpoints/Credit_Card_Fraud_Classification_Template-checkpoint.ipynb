{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f953bf",
   "metadata": {},
   "source": [
    "# ðŸ§ª Credit Card Fraud Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing & Modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# Imbalanced Techniques\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Anomaly Detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Deep Learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfada394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()\n",
    "\n",
    "# Overview\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "# Class Distribution\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Class Distribution (0: Legit, 1: Fraud)')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Standardize if necessary\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c000f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287bf9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "y_pred_iso = iso.fit_predict(X_test)\n",
    "y_pred_iso = [1 if x == -1 else 0 for x in y_pred_iso]\n",
    "\n",
    "print(classification_report(y_test, y_pred_iso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415acc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_embedded = tsne.fit_transform(X_train[:5000])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=y_train[:5000], palette='coolwarm')\n",
    "plt.title('t-SNE visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0439d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_smote, y_smote)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_smote.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_smote, y_smote, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242ec85",
   "metadata": {},
   "source": [
    "### âœ… Conclusion\n",
    "- Compare model metrics (F1-score, Precision-Recall, AUC).\n",
    "- Logistic Regression may give good interpretability, but XGBoost/LightGBM can give better performance.\n",
    "- Neural Network can capture nonlinear patterns but may need tuning.\n",
    "- Consider ensembling, feature selection, or model saving for deployment in future iterations."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
